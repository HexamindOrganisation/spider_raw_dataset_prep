{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a csv file with as columns the database id and the sqlite file name, for the test databases\n",
    "# the test databases are located in ./spider/test_database\n",
    "# in this folder are located folders with the name of the database, and in each folder there is a sqlite file that can have any name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the dataset into a csv file from the json file\n",
    "import json\n",
    "import csv\n",
    "\n",
    "def extract_data(json_file, csv_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    with open(csv_file, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(data[0].keys())\n",
    "        for row in data:\n",
    "            writer.writerow(row.values())\n",
    "\n",
    "json_file = './spider/test_data/dev.json'\n",
    "csv_file = './spider/test_spider.csv'\n",
    "extract_data(json_file, csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbid_to_schema(db_id):\n",
    "    with open('./spider/test_database/' + db_id + '/schema.sql') as f:\n",
    "        lines = f.readlines()\n",
    "    return lines\n",
    "\n",
    "# get all db_ids in the ./spider/test_database folder\n",
    "import os\n",
    "db_ids_train = os.listdir('./spider/test_database')\n",
    "db_ids_train = [db_id for db_id in db_ids_train if os.path.isdir('./spider/test_database/' + db_id)]\n",
    "\n",
    "# remove from list all db_ids who do not have a schema.sql file, and put them in a new list\n",
    "db_ids_no_schema = []\n",
    "for db_id in db_ids_train:\n",
    "    try:\n",
    "        dbid_to_schema(db_id)\n",
    "    except:\n",
    "        db_ids_no_schema.append(db_id)\n",
    "db_ids_train = [db_id for db_id in db_ids_train if db_id not in db_ids_no_schema]\n",
    "\n",
    "# remove from the no_schema list all db_ids who do not have a .sql file, and put them in a new list\n",
    "db_ids_no_sql = ['art_1', 'chinook_1', 'company_1', 'epinions_1', 'flight_4', 'icfp_1', 'small_bank_1', 'twitter_1', 'voter_1', 'world_1']\n",
    "db_ids_no_schema = [db_id for db_id in db_ids_no_schema if db_id not in db_ids_no_sql]\n",
    "\n",
    "# add outliers:\n",
    "db_ids_outliers = ['college_1', 'college_2']\n",
    "schema_outliers = ['TinyCollege.sql', 'TextBookExampleSchema.sql']\n",
    "\n",
    "# remove all outliers from db_ids_no_schema\n",
    "db_ids_no_schema = [db_id for db_id in db_ids_no_schema if db_id not in db_ids_outliers]\n",
    "\n",
    "# remove the db_ids_no_sql from the test_spider.csv file\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./spider/test_spider.csv')\n",
    "df = df[~df['db_id'].isin(db_ids_no_sql)]\n",
    "df = df[~df['db_id'].isin(db_ids_no_schema)]\n",
    "df = df[~df['db_id'].isin(db_ids_outliers)]\n",
    "df.to_csv('./spider/test_spider.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# check if there are sqlite files in the database folders\n",
    "db_ids_no_sqlite = []\n",
    "for db_id in db_ids_train:\n",
    "    try:\n",
    "        db_id + '.sqlite' in os.listdir('./spider/test_database/' + db_id)\n",
    "    except:\n",
    "        db_ids_no_sqlite.append(db_id)\n",
    "print(db_ids_no_sqlite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one csv file with two columns: db_id and schema\n",
    "import csv\n",
    "csv_file = './spider/test_database_schema.csv'\n",
    "\n",
    "with open(csv_file, 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['db_id', 'schema'])\n",
    "    for db_id in db_ids_no_schema:\n",
    "        with open('./spider/test_database/' + db_id + '/' + db_id + '.sql') as f:\n",
    "            schema = f.readlines()\n",
    "            # remove insert statements\n",
    "            # remove all INSERT lines from the schema except one per table\n",
    "            kept_inserts = []\n",
    "            used_tables = []\n",
    "            for line in schema:\n",
    "                if line.startswith('INSERT') or line.startswith('insert') or line.startswith(' insert') or line.startswith(' INSERT') or line.startswith('Insert') or line.startswith(' Insert') or line.startswith('\\tINSERT') or line.startswith('\\tinsert') or line.startswith('\\tInsert'):\n",
    "                    line_tokens = line.split()\n",
    "                    table_name = line_tokens[2]\n",
    "                    # remove all the line after the fourth occurence of ')'\n",
    "                    if line.count(')') > 4:\n",
    "                        first_find = line.find(')')\n",
    "                        second_find = line.find(')', first_find + 1)\n",
    "                        third_find = line.find(')', second_find + 1)\n",
    "                        fourth_find = line.find(')', third_find + 1)\n",
    "                        line = line[:line.find(')', fourth_find + 1)] + ')'              \n",
    "                    if table_name in used_tables:\n",
    "                        continue\n",
    "                    else:\n",
    "                        used_tables.append(table_name)\n",
    "                        kept_inserts.append(line)\n",
    "            schema = [line for line in schema if not line.startswith('INSERT') and not line.startswith('insert') \n",
    "                      and not line.startswith(' insert') and not line.startswith(' INSERT')\n",
    "                      and not line.startswith('Insert') and not line.startswith(' Insert')\n",
    "                      and not line.startswith('\\tINSERT') and not line.startswith('\\tinsert') and not line.startswith('\\tInsert')]\n",
    "            schema = schema + kept_inserts\n",
    "            schema = ''.join(schema)\n",
    "        writer.writerow([db_id, schema])\n",
    "    for db_id in db_ids_train:\n",
    "        schema = dbid_to_schema(db_id)\n",
    "        # remove insert statements\n",
    "        # remove all INSERT lines from the schema except one per table\n",
    "        kept_inserts = []\n",
    "        used_tables = []\n",
    "        for line in schema:\n",
    "            if line.startswith('INSERT') or line.startswith('insert') or line.startswith(' insert') or line.startswith(' INSERT') or line.startswith('Insert') or line.startswith(' Insert') or line.startswith('\\tINSERT') or line.startswith('\\tinsert') or line.startswith('\\tInsert'):\n",
    "                line_tokens = line.split()\n",
    "                table_name = line_tokens[2]\n",
    "                # remove all the line after the fourth occurence of ')'\n",
    "                if line.count(')') > 4:\n",
    "                    first_find = line.find(')')\n",
    "                    second_find = line.find(')', first_find + 1)\n",
    "                    third_find = line.find(')', second_find + 1)\n",
    "                    fourth_find = line.find(')', third_find + 1)\n",
    "                    line = line[:line.find(')', fourth_find + 1)] + ')'  \n",
    "                if table_name in used_tables:\n",
    "                    continue\n",
    "                else:\n",
    "                    used_tables.append(table_name)\n",
    "                    kept_inserts.append(line)\n",
    "        schema = [line for line in schema if not line.startswith('INSERT') and not line.startswith('insert') \n",
    "                    and not line.startswith(' insert') and not line.startswith(' INSERT')\n",
    "                    and not line.startswith('Insert') and not line.startswith(' Insert')\n",
    "                    and not line.startswith('\\tINSERT') and not line.startswith('\\tinsert') and not line.startswith('\\tInsert')]\n",
    "        schema = schema + kept_inserts\n",
    "        schema = ''.join(schema)\n",
    "        writer.writerow([db_id, schema])\n",
    "    for db_id in db_ids_outliers:\n",
    "        with open('./spider/test_database/' + db_id + '/' + schema_outliers[db_ids_outliers.index(db_id)]) as f:\n",
    "            schema = f.readlines()\n",
    "            # remove insert statements\n",
    "            # remove all INSERT lines from the schema except one per table\n",
    "            kept_inserts = []\n",
    "            used_tables = []\n",
    "            for line in schema:\n",
    "                if line.startswith('INSERT') or line.startswith('insert') or line.startswith(' insert') or line.startswith(' INSERT') or line.startswith('Insert') or line.startswith(' Insert') or line.startswith('\\tINSERT') or line.startswith('\\tinsert') or line.startswith('\\tInsert'):\n",
    "                    line_tokens = line.split()\n",
    "                    table_name = line_tokens[2]\n",
    "                    # remove all the line after the fourth occurence of ')'\n",
    "                    if line.count(')') > 4:\n",
    "                        first_find = line.find(')')\n",
    "                        second_find = line.find(')', first_find + 1)\n",
    "                        third_find = line.find(')', second_find + 1)\n",
    "                        fourth_find = line.find(')', third_find + 1)\n",
    "                        line = line[:line.find(')', fourth_find + 1)] + ')'  \n",
    "                    if table_name in used_tables:\n",
    "                        continue\n",
    "                    else:\n",
    "                        used_tables.append(table_name)\n",
    "                        kept_inserts.append(line)\n",
    "            schema = [line for line in schema if not line.startswith('INSERT') and not line.startswith('insert') \n",
    "                    and not line.startswith(' insert') and not line.startswith(' INSERT')\n",
    "                    and not line.startswith('Insert') and not line.startswith(' Insert')\n",
    "                    and not line.startswith('\\tINSERT') and not line.startswith('\\tinsert') and not line.startswith('\\tInsert')]\n",
    "            schema = schema + kept_inserts\n",
    "            schema = ''.join(schema)\n",
    "        writer.writerow([db_id, schema])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add insert statements to schema when it is missing\n",
    "\n",
    "import pandas as pd\n",
    "db_ids_not_insert = []\n",
    "df = pd.read_csv('./spider/test_database_schema.csv')\n",
    "db_ids = df['db_id'].tolist()\n",
    "for db_id in db_ids:\n",
    "    schema = df[df['db_id'] == db_id]['schema'].values[0]\n",
    "    if ('INSERT' or 'insert' or 'Insert') not in schema:\n",
    "        db_ids_not_insert.append(db_id)\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "def get_values(db_id):\n",
    "    conn = sqlite3.connect(f'./spider/test_database/{db_id}/{db_id}.sqlite')\n",
    "    conn.text_factory = lambda b: b.decode(errors = 'ignore')\n",
    "    tables = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()\n",
    "    values = []\n",
    "    for table in tables:\n",
    "        table_name = table[0]\n",
    "        value = conn.execute(f\"SELECT * FROM {table_name}\").fetchall()[:2]\n",
    "        values.append(value)\n",
    "    conn.close()\n",
    "    return tables, values\n",
    "\n",
    "for db_id in db_ids_not_insert:\n",
    "    tables, values = get_values(db_id)\n",
    "    inserts = []\n",
    "    for i, table in enumerate(tables):\n",
    "        table_name = table[0]\n",
    "        if len(values[i]) != 0:\n",
    "            insert = f'INSERT INTO {table_name} VALUES {values[i]}\\n'\n",
    "            inserts.append(insert)\n",
    "    inserts = '\\n'.join(inserts)\n",
    "    df.loc[df['db_id'] == db_id, 'schema'] = df.loc[df['db_id'] == db_id, 'schema'] + inserts\n",
    "df.to_csv('./spider/test_database_schema.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new csv files for the train and dev datasets with only db_id, query and question, but without the schema\n",
    "\n",
    "def clean_csv(csv_file, new_csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    new_df = pd.DataFrame(columns=['db_id', 'query', 'question'])\n",
    "    for i in range(len(df)):\n",
    "        sample = df.iloc[i].to_dict()\n",
    "        sample = sample['db_id'], sample['query'], sample['question']\n",
    "        new_df.loc[i] = sample\n",
    "    new_df.to_csv(new_csv_file, index=False)\n",
    "\n",
    "clean_csv('./spider/test_spider.csv', './spider/test_spider_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_schema(sample):\n",
    "    db_id = sample['db_id']\n",
    "    with open('./spider/test_database/' + db_id + '/schema.sql') as f:\n",
    "        lines = f.readlines()\n",
    "    new_sample = {}\n",
    "    # concatenate the schema to a single string\n",
    "    lines = ' '.join(lines)\n",
    "    new_sample['schema'] = lines\n",
    "    new_sample['query'] = sample['query']\n",
    "    new_sample['question'] = sample['question']\n",
    "    new_sample['db_id'] = db_id\n",
    "    return new_sample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
